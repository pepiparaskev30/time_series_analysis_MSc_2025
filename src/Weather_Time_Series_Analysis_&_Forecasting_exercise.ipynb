{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title ## Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î²Î¹Î²Î»Î¹Î¿Î¸Î·ÎºÏÎ½\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import KNNImputer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from scipy.stats import kruskal\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from prophet import Prophet\n"
      ],
      "metadata": {
        "id": "hrxDiAsFR6Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÏ…Î½ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½\n",
        "\n",
        "def load_data_and_print_sample(pathfile:str):\n",
        "    '''\n",
        "    Args:\n",
        "      pathfile: The file to be used including the times-series data\n",
        "\n",
        "    Output: dataframe with the time series\n",
        "    '''\n",
        "\n",
        "    df = pd.read_csv(pathfile, parse_dates=['date'], index_col='date')\n",
        "    print(df.head(30))\n",
        "    print(\"\\n\")\n",
        "    print(f\" the dataset's columns are: {list(df.columns)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "pathfile = \"/content/training_set.csv\"\n",
        "df = load_data_and_print_sample(pathfile)\n",
        "\n",
        "\n",
        "# Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Ï Î´ÏÎ¿ ÏƒÏ„Î¹Î³Î¼Î¹ÏŒÏ„Ï…Ï€Î± Ï„Î¿Ï… ÏƒÏ…Î½ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:\n",
        " # 1. Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î¼Îµ Ï‡ÏÎ®ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ (ARIMA etc)\n",
        "df_for_statistics = df.copy()\n",
        "\n",
        " # 2. Î³Î¹Î± Î±Î½Î¬Î»Ï…ÏƒÎ· ÎºÎ±Î¹ Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î¼Îµ Ï‡ÏÎ®ÏƒÎ·  Î¼Î¿Î½Ï„Î­Î»Ï‰Î½ Machine/Deep Learning (LSTM, Prophet etc)\n",
        "df_for_ml = df.copy()"
      ],
      "metadata": {
        "id": "2ZZ9gALhZoLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î•Î¼Ï†Î±Î½Î¹ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½\n",
        "df.describe()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-LqRw5-li8Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬Ï‚\n",
        "# Select only numeric columns\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "# Plot each numeric column over time\n",
        "plt.figure(figsize=(15, 8))\n",
        "# Create a separate plot for each numeric column\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df.index, df[col])\n",
        "    plt.title(f\"Time Series of {col}\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(col)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n1meFbTujJ0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÎšÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹ÎºÏÎ½ Î¼ÎµÏ„Î±Î²Î»Î·Ï„ÏÎ½\n",
        "#\n",
        "encoder = LabelEncoder()\n",
        "df['wnd_dir'] = encoder.fit_transform(df['wnd_dir'])\n",
        "\n",
        "# Display the unique mappings\n",
        "label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "print(\"Label encoding mapping for 'wnd_dir':\", label_mapping)\n",
        "\n",
        "# Show the updated DataFrame\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nsho71Ynh6U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¤Î¬ÏƒÎ· Î¼Îµ Ï‡ÏÎ®ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¿Ï Ï„Î­ÏƒÏ„\n",
        "\n",
        "# A. Î”Î¿ÎºÎ¹Î¼Î® Augmented Dickey-Fuller (ADF) Î³Î¹Î± Î£Ï„Î±ÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î± (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¬ÏƒÎ·)\n",
        "# ÎœÎ·Î´ÎµÎ½Î¹ÎºÎ® Ï…Ï€ÏŒÎ¸ÎµÏƒÎ·: Î— Ï‡ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬ Î”Î•Î ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î±ÏƒÎ¹Î¼Î® (Î´Î·Î». Î­Ï‡ÎµÎ¹ Ï„Î¬ÏƒÎ·).\n",
        "# Î‘Î½ p-value < 0.05 â†’ Î±Ï€Î¿ÏÏÎ¯Ï€Ï„ÎµÏ„Î±Î¹ Î· Î¼Î·Î´ÎµÎ½Î¹ÎºÎ® â†’ Î· ÏƒÎµÎ¹ÏÎ¬ ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î±ÏƒÎ¹Î¼Î®.\n",
        "\n",
        "def adf_test(df, cols):\n",
        "    # Î‘Î½ ÎµÎ¯Î½Î±Î¹ Î¼Î¯Î± ÏƒÏ„Î®Î»Î· (string), Ï„Î¿ ÎºÎ¬Î½Î¿Ï…Î¼Îµ Î»Î¯ÏƒÏ„Î±\n",
        "    if isinstance(cols, str):\n",
        "        cols = [cols]\n",
        "\n",
        "    # Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚\n",
        "    numeric_cols = df.select_dtypes(include='number').columns\n",
        "    target_cols = [col for col in cols if col in numeric_cols]\n",
        "\n",
        "    for col in target_cols:\n",
        "        series = df[col].dropna()\n",
        "        result = adfuller(series)\n",
        "\n",
        "        print(f\"ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ADF Î³Î¹Î± Ï„Î· ÏƒÏ„Î®Î»Î· '{col}':\")\n",
        "        print(f\"  Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏŒ ADF: {result[0]:.4f}\")\n",
        "        print(f\"  p-value: {result[1]:.4f}\")\n",
        "        if result[1] < 0.05:\n",
        "            print(\"  âœ… Î£Ï„Î±ÏƒÎ¹Î¼Î® ÏƒÎµÎ¹ÏÎ¬ (Ï‡Ï‰ÏÎ¯Ï‚ Ï„Î¬ÏƒÎ·)\")\n",
        "        else:\n",
        "            print(\"  âŒ ÎœÎ· ÏƒÏ„Î±ÏƒÎ¹Î¼Î® ÏƒÎµÎ¹ÏÎ¬ (Ï€Î¹Î¸Î±Î½ÏÏ‚ Î¼Îµ Ï„Î¬ÏƒÎ·)\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "\n",
        "adf_test(df, \"pollution\")"
      ],
      "metadata": {
        "id": "1kHHrEk9f9wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î•Ï€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î± Î¼Îµ Ï‡ÏÎ®ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¿Ï Ï„Î­ÏƒÏ„\n",
        "\n",
        "\n",
        "def kruskal_seasonality(df, freq='hour'):\n",
        "    df_ = df.copy()\n",
        "    df_['season'] = getattr(df_.index, freq)\n",
        "\n",
        "    numeric_cols = df_.select_dtypes(include='number').columns\n",
        "    for col in numeric_cols:\n",
        "        groups = [group[col].dropna().values for name, group in df_.groupby('season')]\n",
        "        stat, p = kruskal(*groups)\n",
        "        print(f\"Kruskal-Wallis Î³Î¹Î± '{col}' ÎºÎ±Ï„Î¬ {freq}: p = {p:.4f}\", \"âœ… Î•Ï€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±\" if p < 0.05 else \"âŒ ÎŒÏ‡Î¹ ÎµÏ€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±\")\n",
        "\n",
        "kruskal_seasonality(df)"
      ],
      "metadata": {
        "id": "q6kRP1tfonDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î•Ï€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ Î¼Îµ Ï‡ÏÎ®ÏƒÎ· Î´Î¹Î±Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î±Ï…Ï„Î¿ÏƒÏ…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ·Ï‚ (autocorrelation plot)\n",
        "\n",
        "def plot_acf_for_columns(df, cols, lags=50):\n",
        "\n",
        "    if isinstance(cols, str):\n",
        "        cols = [cols]\n",
        "\n",
        "    for col in cols:\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            series = df[col].dropna()\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plot_acf(series, lags=lags)\n",
        "            plt.title(f\"ACF Î³Î¹Î± Ï„Î· ÏƒÏ„Î®Î»Î· '{col}'\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"âŒ Î— ÏƒÏ„Î®Î»Î· '{col}' Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ®.\")\n",
        "\n",
        "plot_acf_for_columns(df, 'temp')"
      ],
      "metadata": {
        "id": "6lPyEFhwnCFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î•Î¾Î¬Î»ÎµÎ¹ÏˆÎ· ÎµÏ€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚\n",
        "def decompose_and_plot(series, name, freq):\n",
        "    result = seasonal_decompose(series.dropna(), model='additive', period=freq)\n",
        "    result.plot()\n",
        "    plt.suptitle(f\"Î‘Ï€Î¿ÏƒÏÎ½Î¸ÎµÏƒÎ· Î§ÏÎ¿Î½Î¿ÏƒÎµÎ¹ÏÎ¬Ï‚: {name}\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def remove_seasonality(df, period):\n",
        "    df = df.copy()\n",
        "    deseasoned_df = pd.DataFrame(index=df.index)\n",
        "    numeric_cols = df.select_dtypes(include='number').columns\n",
        "    for col in numeric_cols:\n",
        "        try:\n",
        "            # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· ÎµÏ€Î¿Ï‡Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ Î¼Î­ÏƒÏ‰ Î±Ï€Î¿ÏƒÏÎ½Î¸ÎµÏƒÎ·Ï‚\n",
        "            result = seasonal_decompose(df[col].dropna(), model='additive', period=period, extrapolate_trend='freq')\n",
        "            deseasoned_series = df[col] - result.seasonal\n",
        "            deseasoned_df[col] = deseasoned_series\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Î±Ï€Î¿ÏƒÏÎ½Î¸ÎµÏƒÎ· Î³Î¹Î± Ï„Î· ÏƒÏ„Î®Î»Î· '{col}': {e}\")\n",
        "\n",
        "    return deseasoned_df\n",
        "\n",
        "decompose_and_plot(df['pollution'], 'Pollution', 1)\n",
        "df_statistics_no_seasonality = remove_seasonality(df_for_statistics, 24)\n",
        "\n",
        "print(df_statistics_no_seasonality)"
      ],
      "metadata": {
        "id": "qeETeglRlxa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ…Î½ÏŒÎ»Î¿Ï… Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¿Ï Ï€ÏÎ¿Ï‚ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·\n",
        "\n",
        "def train_test_split_df_with_target(df, target_col='pollution', test_size=0.2):\n",
        "    \"\"\"\n",
        "    Î”Î¹Î±Ï‡Ï‰ÏÎ¯Î¶ÎµÎ¹ df ÏƒÎµ X (features), y (target), ÎºÎ±Î¹ Ï„Î± Ï‡Ï‰ÏÎ¯Î¶ÎµÎ¹ ÏƒÎµ train/test\n",
        "    \"\"\"\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    split_point = int(len(df) * (1 - test_size))\n",
        "\n",
        "    X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]\n",
        "    y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "vzDfVXdTsZOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Î¿Î½Ï„Î­Î»Î± Î³Î¹Î± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·: ARIMA, ExponentialSmoothing\n",
        "def arima_model(series):\n",
        "    return ARIMA(series, order=(2, 0, 2))\n",
        "\n",
        "def ets_model(series):\n",
        "    return ExponentialSmoothing(series, trend='add', seasonal=None, damped_trend=True)\n"
      ],
      "metadata": {
        "id": "njb6dN7suWs3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Ï„Î·Î½ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½ Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿\n",
        "\n",
        "def evaluate_forecasting_model(model_func, y_train, y_test, model_name):\n",
        "    model = model_func(y_train)\n",
        "    fit = model.fit()\n",
        "    forecast = fit.forecast(steps=len(y_test))\n",
        "\n",
        "    # ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚\n",
        "    mse = mean_squared_error(y_test, forecast)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, forecast)\n",
        "\n",
        "    print(f\"ğŸ“Š {model_name}\")\n",
        "    print(f\"  MSE  : {mse:.3f}\")\n",
        "    print(f\"  RMSE : {rmse:.3f}\")\n",
        "    print(f\"  RÂ²   : {r2:.3f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    return forecast, mse, rmse, r2\n"
      ],
      "metadata": {
        "id": "KBbhzQREvj9p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Ï„Î·Î½ Î¿Ï€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½\n",
        "def plot_forecasts(y_test, forecasts, labels):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(y_test.index, y_test.values, label='Actual', linewidth=2)\n",
        "\n",
        "    for forecast, label in zip(forecasts, labels):\n",
        "        plt.plot(y_test.index, forecast, label=label)\n",
        "\n",
        "    plt.title('Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î¼Îµ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î±')\n",
        "    plt.xlabel('Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±')\n",
        "    plt.ylabel('Î¡ÏÏ€Î±Î½ÏƒÎ· (pollution)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WdJpchnHwwce",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Î•Ï†Î±ÏÎ¼Î¿Î³Î® Î¼Î¿Î½Ï„Î­Î»Ï‰Î½\n",
        "# Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· / ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚\n",
        "X_train_stat, X_test_stat, y_train_stat, y_test_stat = train_test_split_df_with_target(df_statistics_no_seasonality)\n",
        "print(X_train_stat.shape, y_train_stat.shape)\n",
        "print(X_test_stat.shape, y_test_stat.shape)\n",
        "\n",
        "# ÎœÎ¿Î½Ï„Î­Î»Î± ÎºÎ±Î¹ ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ·\n",
        "forecast_arima, mse_a, rmse_a, r2_a = evaluate_forecasting_model(arima_model, y_train_stat, y_test_stat, 'ARIMA')\n",
        "forecast_ets, mse_e, rmse_e, r2_e = evaluate_forecasting_model(ets_model, y_train_stat, y_test_stat, 'ETS')\n",
        "\n",
        "# ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·\n",
        "plot_forecasts(y_test_stat, [forecast_arima, forecast_ets], ['ARIMA', 'ETS'])\n"
      ],
      "metadata": {
        "id": "jS56LSCcujak",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î¼Îµ Ï„Î· Ï‡ÏÎ®ÏƒÎ· Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ Î¼Î·Ï‡Î±Î½Î¹ÎºÎ®Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚\n",
        "# Drop non-numeric columns\n",
        "# Keep only numeric columns\n",
        "df_ml_numeric = df_for_ml.select_dtypes(include=[np.number])\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df_ml_numeric)\n",
        "df_ml_scaled = pd.DataFrame(scaled_data, columns=df_ml_numeric.columns, index=df_ml_numeric.index)\n"
      ],
      "metadata": {
        "id": "UTc0qoTPf-L9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## Long Short-Term Memory  (LSTM) Model\n",
        "\n",
        "# Select the target variable (e.g., 'temp')\n",
        "target_col = \"pollution\"\n",
        "target_data = df_ml_scaled[[target_col]]\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(data, seq_length=24):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(target_data.values)\n",
        "\n",
        "# Train-test split\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train_ml.shape[1], X_train_ml.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_ml, y_train_ml, epochs=20, batch_size=32, validation_data=(X_test_ml, y_test_ml), verbose=1)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test_ml)\n",
        "\n",
        "# Inverse scale predictions for interpretation\n",
        "y_test_inv = scaler.inverse_transform(np.hstack([np.zeros((len(y_test_ml), df_ml_numeric.shape[1]-1)), y_test_ml.reshape(-1, 1)]))[:, -1]\n",
        "y_pred_inv = scaler.inverse_transform(np.hstack([np.zeros((len(y_pred), df_ml_numeric.shape[1]-1)), y_pred]))[:, -1]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test_inv, label=\"Actual\")\n",
        "plt.plot(y_pred_inv, label=\"Predicted\")\n",
        "plt.title(\"LSTM Forecasting - Temperature\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Temperature\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Y0m1n9a5YMp1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  ## Prophet Model\n",
        "\n",
        "# --- PREPARE DATA FOR PROPHET ---\n",
        "df_prophet = df[[target_col]].reset_index().rename(columns={\"date\": \"ds\", target_col: \"y\"})\n",
        "\n",
        "# Split manually based on time\n",
        "split_point = int(len(df_prophet) * 0.8)\n",
        "df_train_prophet = df_prophet.iloc[:split_point]\n",
        "df_test_prophet = df_prophet.iloc[split_point:]\n",
        "\n",
        "# --- FIT PROPHET ---\n",
        "prophet_model = Prophet(daily_seasonality=True)\n",
        "prophet_model.fit(df_train_prophet)\n",
        "\n",
        "# Forecast same length as test\n",
        "future = prophet_model.make_future_dataframe(periods=len(df_test_prophet), freq='H')\n",
        "forecast = prophet_model.predict(future)\n",
        "\n",
        "# --- GET FORECASTED VALUES ---\n",
        "y_test_prophet = df_test_prophet['y'].values\n",
        "y_pred_prophet = forecast.iloc[-len(df_test_prophet):]['yhat'].values\n",
        "\n",
        "# --- METRICS (PROPHET) ---\n",
        "mse_prophet = mean_squared_error(y_test_prophet, y_pred_prophet)\n",
        "rmse_prophet = np.sqrt(mse_prophet)\n",
        "r2_prophet = r2_score(y_test_prophet, y_pred_prophet)\n",
        "\n",
        "print(\"ğŸ“Š Prophet Evaluation:\")\n",
        "print(f\"  MSE  : {mse_prophet:.2f}\")\n",
        "print(f\"  RMSE : {rmse_prophet:.2f}\")\n",
        "print(f\"  RÂ²   : {r2_prophet:.3f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- PLOT PROPHET RESULTS ---\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test_prophet, label=\"Actual\")\n",
        "plt.plot(range(len(y_test_prophet)-200, len(y_test_prophet)), y_pred_prophet[-200:], label=\"Prophet Forecast (last 200)\")\n",
        "plt.title(\"ğŸ“ˆ Prophet Forecast - Pollution\")\n",
        "plt.xlabel(\"Time Step\")\n",
        "plt.ylabel(\"Pollution\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2xHFx57OY8N6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcNn3Bq6Dn29"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}